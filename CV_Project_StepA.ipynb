{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTc8LlaO0lcn"
      },
      "source": [
        "Load needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDCHphZi5gco",
        "outputId": "391b4ee2-690f-4466-f767-32992a768400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx3A3tyrGatq",
        "outputId": "160d13b5-5f96-4448-adc4-1aa40b202774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-contrib-python==4.4.0.44\n",
            "  Downloading opencv_contrib_python-4.4.0.44-cp37-cp37m-manylinux2014_x86_64.whl (55.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 55.7 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==4.4.0.44) (1.19.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-4.4.0.44\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-contrib-python==4.4.0.44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Oj69ynYsQ6b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7OKhzoe0kLS"
      },
      "source": [
        "STEP A: \n",
        "Test on scene image: {e1.png, e2.png, e3.png, e4.png, e5.png}\n",
        "\n",
        "Use product images: {0.jpg, 1.jpg, 11.jpg, 19.jpg, 24.jpg, 26.jpg, 25.jpg}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4jIpcWH9-BQ"
      },
      "outputs": [],
      "source": [
        "scene_paths = [\"e1.png\",\"e2.png\",\"e3.png\",\"e4.png\",\"e5.png\"]\n",
        "model_paths = [\"0.jpg\",\"1.jpg\",\"11.jpg\",\"19.jpg\",\"24.jpg\",\"26.jpg\",\"25.jpg\"]\n",
        "\n",
        "\n",
        "def load_images(paths,dir):\n",
        "  return [cv2.cvtColor(cv2.imread(\"/content/gdrive/My Drive/CV Project/\"+dir+path),cv2.COLOR_BGR2RGB) for path in paths]\n",
        "  \n",
        "# Load scene and model images\n",
        "train_images = load_images(scene_paths,\"scenes/\")\n",
        "query_images = load_images(model_paths,\"models/\")\n",
        "\n",
        "# Compute keypoints and descriptors\n",
        "sift = cv2.SIFT_create()\n",
        "\n",
        "train_features = {index:sift.detectAndCompute(train_image,None) for index,train_image in enumerate(train_images)}\n",
        "query_features = {index:sift.detectAndCompute(query_image,None) for index,query_image in enumerate(query_images)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opMTw5PKXRkH"
      },
      "outputs": [],
      "source": [
        "train_features[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCfTypF7SJwL"
      },
      "outputs": [],
      "source": [
        "def compute_matches(FLANN_INDEX_KDTREE,trees,checks,k,lowe,des_query,des_train):\n",
        "  index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = trees)\n",
        "  search_params = dict(checks = checks)\n",
        "  flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "  matches = flann.knnMatch(des_query,des_train,k=2)\n",
        "  # store all the good matches as per Lowe's ratio test.\n",
        "  good = []\n",
        "  for m,n in matches:\n",
        "      if m.distance < lowe*n.distance:\n",
        "          good.append(m)\n",
        "  return good\n",
        "\n",
        "# Get the dominant color in the image with Kmeans clustering\n",
        "def get_dom_color(img_in):\n",
        "  Z = img_in.reshape((-1,3))\n",
        "  Z = np.float32(Z)\n",
        "  # define criteria, number of clusters(K) and apply kmeans()\n",
        "  criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "  K = 1\n",
        "  ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
        "  # Now convert back into uint8, and make original image\n",
        "  center = np.uint8(center)\n",
        "  res = center[label.flatten()]\n",
        "  res2 = res.reshape((img_in.shape))\n",
        "  return res2[0][0]\n",
        "\n",
        "def get_roi(x1,x2,x3,x4,y1,y2,y3,y4,img):\n",
        "  top_left_x = int(max(0,min([x1,x2,x3,x4])))\n",
        "  top_left_y = int(max(0, min([y1,y2,y3,y4])))\n",
        "  bot_right_x = int(max([x1,x2,x3,x4]))\n",
        "  bot_right_y = int(max([y1,y2,y3,y4]))\n",
        "  return img[top_left_y:bot_right_y, top_left_x:bot_right_x]\n",
        "\n",
        "def cluster_kp(keypoints, quantile = 0.22):\n",
        "      x = np.array([keypoint.pt[0] for keypoint in keypoints]).reshape(-1,1) \n",
        "      bandwidth = estimate_bandwidth(x, quantile=0.22)\n",
        "      ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, cluster_all=True)\n",
        "      ms.fit(x)\n",
        "      return ms.labels_, len(np.unique(ms.labels_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEKB42u9w09d"
      },
      "outputs": [],
      "source": [
        "def object_retrieve(img_query, img_train, query_features, train_features, min_match_count = 50, COLOR_DIFF_THRESHOLD = 50, verbose = False):\n",
        "    # Partition the keypoints of train image into clusters\n",
        "    labels,n_clusters = cluster_kp(train_features[0])\n",
        "    # We analyze each cluster \n",
        "    for i in range(n_clusters):\n",
        "      # Compute the matches on the subset of keypoints\n",
        "      key_train_local = np.array(train_features[0])[labels == i]\n",
        "      des_train_local = np.array(train_features[1])[labels == i]\n",
        "      good = compute_matches(0,5,50,2,0.55,query_features[1],des_train_local)\n",
        "      # If it's a good match, then proceed with the detection\n",
        "      if len(good)>min_match_count:\n",
        "          src_pts = np.float32([query_features[0][m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "          dst_pts = np.float32([key_train_local[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
        "          M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 2)\n",
        "          if M is None:\n",
        "              print (\"No Homography was found\")\n",
        "          else:\n",
        "              h,w,_ = img_query.shape\n",
        "              # Generate and plot the rectangle into the target image\n",
        "              pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
        "              dst = cv2.perspectiveTransform(pts,M)\n",
        "              roi = get_roi(dst[0][0][0],dst[1][0][0],dst[2][0][0],dst[3][0][0],dst[0][0][1],dst[1][0][1],dst[2][0][1],dst[3][0][1],img_train)\n",
        "              # If we can manage to obtain a rectangle, then we proceed\n",
        "              if len(roi):\n",
        "                # check if the euclidean distance between the colors (mean) of the two rectangle is lower than the chosen threshold\n",
        "                color_diff = np.linalg.norm(roi.mean(axis = 0).mean(axis = 0) - img_query.mean(axis = 0).mean(axis = 0))\n",
        "                if color_diff <= COLOR_DIFF_THRESHOLD:\n",
        "                  print(\"The object was found\")\n",
        "                  return True\n",
        "                else :\n",
        "                  print(\"A match was discarded\")\n",
        "      else:\n",
        "          print(\"Not enough matches were found\")\n",
        "\n",
        "    return False\n",
        "\n",
        "pred_labels = {}\n",
        "# Iterating among all scenes and looking for the query object.\n",
        "for index_train  in range(len(train_images)):\n",
        "  scene_labels = []\n",
        "  for index_query in range(len(query_images)):\n",
        "    scene_labels.append(object_retrieve(query_images[index_query], train_images[index_train], query_features[index_query], train_features[index_train]))\n",
        "  pred_labels[index_train] = scene_labels\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdH0yOvWaux6",
        "outputId": "e26fa71b-a6eb-4f1b-baec-ca50f5382e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "true_labels = {\n",
        "    0: [1,0,1,0,0,0,0],\n",
        "    1: [0,0,0,0,1,1,1],\n",
        "    2: [1,1,1,0,0,0,0],\n",
        "    3: [1,0,1,0,0,1,1],\n",
        "    4: [0,0,0,1,0,0,1],\n",
        "}\n",
        "print(true_labels == pred_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CV_Project_StepA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}